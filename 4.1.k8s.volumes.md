## Working with k8s volumes

K8s provides a Container Storage Interface (CSI) to allow admin users to make use of multiple types of storage to persist data via drivers.

Between some of the [drivers](https://kubernetes-csi.github.io/docs/drivers.html) you can find:

- NFS
- Azure Disk
- Vault
- And more..

The idea is that it does not matter what type of storage you use, there is always a standardize way to use it.

The usage of these drives and its characteristics and parameters are configured by a StorageClass. With this object we can choose the driver and the parameters to configure the driver in k8s as a manifest.

A k8s cluster can use multiple storage classes in the same installation.

## Storage classes

In microk8s, and mostly all single node k8s, we can make use of the hostpath storage class. This type of storage makes of use of the local filesystem of the node to persist data, instead of a virtual disk.

To list the available storage classes in the cluster you can run the following command:

```yaml
kubectl get storageclass
```

You can also describe the storage class available

```yaml
kubectl describe storageclass microk8s-hostpath
```


## Persisten Volume Claim

To use the storage class we can define k8s objects called PersistenVolumeClaim, they will generate a Volume for us to be used by the pods or deployments.

In this example, we are generating a PVC with 1 Gb of memory and the access mode as `ReadWriteOnce`, this means that the volume will only be able to be mounted in one single pod.

```yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: some-data
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 1Gi
```

After the PVC is declared, we can mounted as a directory in a pod by adding two important configurations:

1. `volumes` attribute. Here we declare a volume referencing the PVC

```yaml
volumes:
  - name: pv-storage
    persistentVolumeClaim:
      claimName: some-data
```

2. In the containers specification, we indicate in which directory in the filesystem we want to mount the disk

```yaml
volumeMounts:
  - mountPath: "/usr/share/nginx/html"
    name: pv-storage
```


```yaml
apiVersion: v1
kind: Pod
metadata:
  name: pv-pod
spec:

  volumes:
    - name: pv-storage
      persistentVolumeClaim:
        claimName: some-data


  containers:
    - name: pv-container
      image: ubuntu
      command:
      - sleep
      - "3600"

      volumeMounts:
        - mountPath: "/usr/share/nginx/html"
          name: pv-storage
```

We are creating this pod with ubuntu to install VIM and create and edit a html file inside the mount directory as follows:

```bash
kubectl exec -it pv-pod -- bash

# install VI to modify the file
apt update && apt install vim -qqy

# Change something in the file and exit
vim /usr/share/nginx/html/index.html

# Hi,
# I am a file stored in a volume
```

After the file is created we can delete the pod

```bash
kubectl delete pod pv-pod
```

Now create a new pod again, this time with nginx, the webserver that will serve the file.

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: pv-pod
spec:

  volumes:
    - name: pv-storage
      persistentVolumeClaim:
        claimName: some-data


  containers:
    - name: pv-container
      image: nginx
      ports:
        - containerPort: 80
          name: "http-server"

      volumeMounts:
        - mountPath: "/usr/share/nginx/html"
          name: pv-storage
```

You can use the command `kubectl port-forward` to forward traffic directly to the pod without creating a new service and ingress.

```bash
kubectl port-forward --address 0.0.0.0 pod/pv-pod 8888:80
```

As you can see, data remains in the cluster even though the pods are removed and recreated.